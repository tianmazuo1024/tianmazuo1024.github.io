import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as o,o as a,d as c}from"./app-B5m7CcSj.js";const d={},r=c('<figure><img src="https://tianmazuo.com/technology/bigdata/hbase/hbase-05.png" alt="HBase整体架构" tabindex="0" loading="lazy"><figcaption>HBase整体架构</figcaption></figure><h2 id="hregion" tabindex="-1"><a class="header-anchor" href="#hregion"><span>HRegion</span></a></h2><ul><li><p>每个<code>HRegionServer</code>包含一个<code>HLog</code>和多个<code>HRegion</code>。</p></li><li><p><code>HLog</code>负责日志记录，针对<code>HRegionServer</code>的所有写操作（例如<code>put</code>、<code>delete</code>等）都会先记录到这个日志中，然后再把数据写到对应的<code>HRegion</code>。</p></li><li><p><code>HRegion</code>负责数据的存储，它的表面意思是<code>区域</code>，<a href="https://hbase.apache.org/" target="_blank" rel="noopener noreferrer">HBase</a>表中的数据会按照行被横向划分为多个<code>Region</code>。</p></li><li><p>每个<code>HRegion</code>按照存储的最小<code>RowKey</code>和最大<code>RowKey</code>指定，也就是个<code>HRegion</code>包含的区间为<code>[startRowKey, endRowKey)</code>，<code>RowKey</code>是按升序排列的。</p></li><li><p>每一个<code>列族</code>在<a href="https://hbase.apache.org/" target="_blank" rel="noopener noreferrer">HBase</a>中都是一个单独的文件，对应一个<code>Store</code>，每个<code>HRegion</code>中都可能会有多个<code>Store</code>。</p></li></ul><figure><img src="https://tianmazuo.com/technology/bigdata/hbase/hbase-07.png" alt="每个列族都用单独的文件存储" tabindex="0" loading="lazy"><figcaption>每个列族都用单独的文件存储</figcaption></figure><ul><li><p>在向<code>HRegion</code>写数据时，会根据指定的列族信息把数据写到不同的<code>Store</code>里。</p></li><li><p>往<code>Store</code>里写数据时，会先写入<code>MemStore</code>，也就是内存中专门存储<code>Store</code>一块区域。</p></li><li><p>当内存的<code>MemStore</code>写满之后，就会把数据持久化到<code>StoreFile</code>，然后再通过<code>DFS Client</code>写入到<a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html" target="_blank" rel="noopener noreferrer">HDFS</a>的<code>DataNode</code>中。</p></li></ul><figure><img src="https://tianmazuo.com/technology/bigdata/hbase/hbase-08.png" alt="HBase物理存储结构" tabindex="0" loading="lazy"><figcaption>HBase物理存储结构</figcaption></figure><h3 id="hregion-split" tabindex="-1"><a class="header-anchor" href="#hregion-split"><span>HRegion Split</span></a></h3><ul><li><p>由于<a href="https://hbase.apache.org/" target="_blank" rel="noopener noreferrer">HBase</a>默认给每个新建的表只分配1个<code>HRegion</code>，造成所有的读写都集中在一个<code>HRegion</code>上，进而产生读写热点问题。</p></li><li><p>所以当表数据越来越多的时候，<code>HRegion</code>会自动分裂（<code>Split</code>），保证每个<code>HRegion</code>不会太大，便于管理。</p></li></ul><figure><img src="https://tianmazuo.com/technology/bigdata/hbase/hbase-06.png" alt="HRegion自动分裂" tabindex="0" loading="lazy"><figcaption>HRegion自动分裂</figcaption></figure><ul><li><p>原始的<code>HRegion</code>会被分裂成两个新的子<code>HRegion</code>，而自己则被清除。</p></li><li><p>触发<code>HRegion Split</code>的条件是这样的。</p><ul><li><p><code>ConstantSizeRegionSplitPolicy</code>（<a href="https://hbase.apache.org/" target="_blank" rel="noopener noreferrer">HBase</a><code>0.94</code>版本以前的机制）：<code>HRegion</code>中最大的<code>HFile</code>大于设置的阈值大小时被触发，阈值默认10GB。</p></li><li><p><code>IncreasingToUpperBoundRegionSplitPolicy</code>（<a href="https://hbase.apache.org/" target="_blank" rel="noopener noreferrer">HBase</a><code>0.94</code>~<code>2.x</code>版本默认机制）：<code>HRegion</code>中最大的<code>HFile</code>大于设置的阈值大小时被触发，但阈值的大小不是固定的，而是会不断调整的，调整公式为：调整后阈值 = <code>HRegion</code>数量的3次方 × flushsize × 2，但这个不固定的值也有一个上限，通过<code>hbase.hregion.max.filesize</code>来指定。这种方式主要是为了让<code>HRegion</code>能够根据表的大小来自动调整数量。</p></li></ul></li></ul><h3 id="hregion-balance" tabindex="-1"><a class="header-anchor" href="#hregion-balance"><span>HRegion Balance</span></a></h3><ul><li><p>当<code>HRegion</code>分裂之后，就会涉及到<code>HRegion</code>的访问策略了。<code>HMaster</code>会对根据负载均衡策略重新均匀地分配<code>HRegion</code>所属的<code>HRegionServer</code>，最大化发挥分布式系统的优势。</p></li><li><p><a href="https://hbase.apache.org/" target="_blank" rel="noopener noreferrer">HBase</a>目前支持两种<code>HRegion</code>分配策略。</p><ul><li><p><code>DefaultLoadBalancer</code>：它保证每个<code>HRegionServer</code>中的<code>HRegion</code>数量基本上相等，但如果有的<code>HRegion</code>数据多，有的数据少，就会造成访问不均衡的问题。</p></li><li><p><code>StochasticLoadBalancer</code>：这种策略比较复杂，因为它对6个方面的因素进行加权计算，算出一个代价值，用这个数值来评估当前<code>HRegion</code>分布是否均衡，越均衡代价值就越低。这个6个因素包括：<code>每台服务器读请求数</code>、<code>每台服务器写请求数</code>、<code>HRegion个数</code>、<code>移动数据的代价</code>、<code>数据Locality</code>和<code>每张表占用HRegion数量的上限</code>。</p></li></ul></li></ul><br><h2 id="wal预写日志" tabindex="-1"><a class="header-anchor" href="#wal预写日志"><span>WAL预写日志</span></a></h2><ul><li><p><code>WAL</code>是<code>Write-Ahead-Logging</code>，也就是<code>预写日志</code>的简称。</p></li><li><p>所有只要是有写日志这一环节的存储系统，不管是<a href="https://www.mysql.com" target="_blank" rel="noopener noreferrer">MySQL</a>、<a href="https://hadoop.apache.org" target="_blank" rel="noopener noreferrer">Hadoop</a>还是<a href="https://hbase.apache.org/" target="_blank" rel="noopener noreferrer">HBase</a>，日志的最主要作用就是用于<code>容灾备份</code>或<code>灾难恢复</code>。</p></li><li><p><code>WAL</code>的作用就类似于<a href="https://www.mysql.com" target="_blank" rel="noopener noreferrer">MySQL</a>中的<code>Binlog</code>，所以一旦写入<code>WAL</code>失败，就意味着整个写操作是失败的。</p></li><li><p><code>HLog</code>就是<code>WAL</code>的实现类。</p></li><li><p><code>WAL</code>保存在<a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html" target="_blank" rel="noopener noreferrer">HDFS</a>中，其目录为<code>/hbase/WALs</code>，针对集群中的每台机器，它都有一个与之对应的目录。</p></li><li><p>因为<code>MemStore</code>会定期将数据写入<code>StoreFile</code>，所以<code>WAL</code>并不会保存所有的写操作，而且它自身也有数据失效策略。</p></li></ul><br><h2 id="hfile" tabindex="-1"><a class="header-anchor" href="#hfile"><span>HFile</span></a></h2><ul><li><p><code>HFile</code>是<a href="https://hbase.apache.org/" target="_blank" rel="noopener noreferrer">HBase</a>中另一个重要的东西，它是<a href="https://hbase.apache.org/" target="_blank" rel="noopener noreferrer">HBase</a>中最小的结构，<a href="https://hbase.apache.org/" target="_blank" rel="noopener noreferrer">HBase</a>所有的数据都是保存在<code>HFile</code>里面的。</p></li><li><p><code>HFile</code>其实就是<a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html" target="_blank" rel="noopener noreferrer">HDFS</a>中保存的文件，但它有自己特殊的格式。</p></li><li><p><code>HFile</code>由6个部分组成。</p><ul><li><p><code>Data</code>：由<code>key-value</code>组成的键值对。</p></li><li><p><code>Meta</code>：元数据块，存储用户自定义的<code>key-value</code>。</p></li><li><p><code>File Info</code>：记录文件信息的定长元数据。</p></li><li><p><code>Data Index</code>：数据块索引，记录每个<code>Data</code>的起始索引。</p></li><li><p><code>Meta Index</code>：元数据索引，记录每个<code>Meta</code>的起始索引。</p></li><li><p><code>Trailer</code>：一个定长的指向其他数据块的起始点，它类似于一个尾部指针。</p></li></ul></li><li><p>当<code>MemStore</code>写满时，就会持久化生成一个<code>StoreFile</code>，这个<code>StoreFile</code>的底层就是<code>HFile</code>。</p></li><li><p>当<code>HFile</code>数量达到一定阈值后，<a href="https://hbase.apache.org/" target="_blank" rel="noopener noreferrer">HBase</a>会对它们执行合并（<code>Compaction</code>）操作，把多个<code>HFile</code>合并成一个，而执行合并操作时，会产生大量的<code>I/O</code>操作。</p></li><li><p><code>HFile</code>的合并分为<code>Major</code>（大合并）和<code>Minor</code>（小合并）两种类型，可以把它们理解为<code>JVM</code>的<code>Full GC</code>和<code>Young GC</code>。</p><ul><li><p><code>Minor</code>：只做部分文件的合并，过程较快且<code>I/O</code>相对较低。</p></li><li><p><code>Major</code>：将<code>HRegion</code>下所有的<code>HFile</code>合并成一个文件，由于涉及到大量的<code>I/O</code>操作，所以对<a href="https://hbase.apache.org/" target="_blank" rel="noopener noreferrer">HBase</a>的性能会产生很大影响，生产环境中需要关闭自动触发大合并的功能，改为手动在业务低谷期触发。</p></li></ul></li></ul><br><h2 id="bloomfilter" tabindex="-1"><a class="header-anchor" href="#bloomfilter"><span>BloomFilter</span></a></h2><ul><li><p><code>BloomFilter</code>是布隆过滤器，它是一种设计巧妙的概率型数据结构，可以<code>过滤出</code>某样一定不存在或者可能存在的东西。</p></li><li><p>它是<a href="https://hbase.apache.org/" target="_blank" rel="noopener noreferrer">HBase</a>中的高级功能，可以减少特定访问模式（<code>get</code>/<code>scan</code>）下的查询时间，准确判断<code>HFile</code>中是否包含所需数据，提高吞吐量。</p></li><li><p>所以<a href="https://hbase.apache.org/" target="_blank" rel="noopener noreferrer">HBase</a>会在生成<code>HFile</code>时，包含一份<code>BloomFilter</code>结构的数据集合。</p></li></ul>',21),t=[r];function i(n,l){return a(),o("div",null,t)}const g=e(d,[["render",i],["__file","architecture.html.vue"]]),s=JSON.parse('{"path":"/technology/bigdata/hbase/architecture.html","title":"HBase底层技术机制","lang":"zh-CN","frontmatter":{"title":"HBase底层技术机制","icon":"barcode","category":["大数据","HBase"],"tag":["大数据","HBase"],"date":"2023-04-03T00:00:00.000Z","isOriginal":true,"star":true,"description":"HBase整体架构HBase整体架构 HRegion 每个HRegionServer包含一个HLog和多个HRegion。 HLog负责日志记录，针对HRegionServer的所有写操作（例如put、delete等）都会先记录到这个日志中，然后再把数据写到对应的HRegion。 HRegion负责数据的存储，它的表面意思是区域，HBase表中的数据会...","head":[["meta",{"property":"og:url","content":"https://vuepress-theme-hope-docs-demo.netlify.app/technology/bigdata/hbase/architecture.html"}],["meta",{"property":"og:site_name","content":"添码座"}],["meta",{"property":"og:title","content":"HBase底层技术机制"}],["meta",{"property":"og:description","content":"HBase整体架构HBase整体架构 HRegion 每个HRegionServer包含一个HLog和多个HRegion。 HLog负责日志记录，针对HRegionServer的所有写操作（例如put、delete等）都会先记录到这个日志中，然后再把数据写到对应的HRegion。 HRegion负责数据的存储，它的表面意思是区域，HBase表中的数据会..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://tianmazuo.com/technology/bigdata/hbase/hbase-05.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:author","content":"添码座"}],["meta",{"property":"article:tag","content":"大数据"}],["meta",{"property":"article:tag","content":"HBase"}],["meta",{"property":"article:published_time","content":"2023-04-03T00:00:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"HBase底层技术机制\\",\\"image\\":[\\"https://tianmazuo.com/technology/bigdata/hbase/hbase-05.png\\",\\"https://tianmazuo.com/technology/bigdata/hbase/hbase-07.png\\",\\"https://tianmazuo.com/technology/bigdata/hbase/hbase-08.png\\",\\"https://tianmazuo.com/technology/bigdata/hbase/hbase-06.png\\"],\\"datePublished\\":\\"2023-04-03T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"添码座\\",\\"url\\":\\"https://www.tianmazuo.com/about/\\"}]}"]]},"headers":[{"level":2,"title":"HRegion","slug":"hregion","link":"#hregion","children":[{"level":3,"title":"HRegion Split","slug":"hregion-split","link":"#hregion-split","children":[]},{"level":3,"title":"HRegion Balance","slug":"hregion-balance","link":"#hregion-balance","children":[]}]},{"level":2,"title":"WAL预写日志","slug":"wal预写日志","link":"#wal预写日志","children":[]},{"level":2,"title":"HFile","slug":"hfile","link":"#hfile","children":[]},{"level":2,"title":"BloomFilter","slug":"bloomfilter","link":"#bloomfilter","children":[]}],"git":{},"readingTime":{"minutes":5.05,"words":1514},"filePathRelative":"technology/bigdata/hbase/architecture.md","localizedDate":"2023年4月3日","excerpt":"<figure><img src=\\"https://tianmazuo.com/technology/bigdata/hbase/hbase-05.png\\" alt=\\"HBase整体架构\\" tabindex=\\"0\\" loading=\\"lazy\\"><figcaption>HBase整体架构</figcaption></figure>\\n<h2>HRegion</h2>\\n<ul>\\n<li>\\n<p>每个<code>HRegionServer</code>包含一个<code>HLog</code>和多个<code>HRegion</code>。</p>\\n</li>\\n<li>\\n<p><code>HLog</code>负责日志记录，针对<code>HRegionServer</code>的所有写操作（例如<code>put</code>、<code>delete</code>等）都会先记录到这个日志中，然后再把数据写到对应的<code>HRegion</code>。</p>\\n</li>\\n<li>\\n<p><code>HRegion</code>负责数据的存储，它的表面意思是<code>区域</code>，<a href=\\"https://hbase.apache.org/\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">HBase</a>表中的数据会按照行被横向划分为多个<code>Region</code>。</p>\\n</li>\\n<li>\\n<p>每个<code>HRegion</code>按照存储的最小<code>RowKey</code>和最大<code>RowKey</code>指定，也就是个<code>HRegion</code>包含的区间为<code>[startRowKey, endRowKey)</code>，<code>RowKey</code>是按升序排列的。</p>\\n</li>\\n<li>\\n<p>每一个<code>列族</code>在<a href=\\"https://hbase.apache.org/\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">HBase</a>中都是一个单独的文件，对应一个<code>Store</code>，每个<code>HRegion</code>中都可能会有多个<code>Store</code>。</p>\\n</li>\\n</ul>","autoDesc":true}');export{g as comp,s as data};
