import{_ as s}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,o as i,d as e}from"./app-CiwSPZKD.js";const r={},t=e(`<h2 id="rdd的概念" tabindex="-1"><a class="header-anchor" href="#rdd的概念"><span>RDD的概念</span></a></h2><ul><li><p><a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>（<code>Resilient Distributed Datasets，弹性分布式数据集</code>）是<a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>提供的一个非常核心的抽象概念，它是一种可以被分为多个<code>分区</code>（<code>Partition</code>）的数据元素的<code>集合</code>。</p></li><li><p>默认情况下，<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>的数据是存放在内存中的，而当内存资源不足时，<a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>会自动将<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>中的数据写入磁盘（这是它之所以具有<code>弹性</code>的原因）。</p></li><li><p><code>分区</code>分布在集群中的不同节点上，所以<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>中的数据可以被并行操作（这是它之所以具有<code>分布式</code>的原因）。</p></li><li><p><a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>只能通过数据创建，它可以是<a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>支持的任意一种数据集合。</p></li><li><p><a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>最重要的特性就是<code>容错性</code>，它可以自动从节点失败中恢复过来。即如果某个节点上的<code>分区</code>因为节点故障，导致数据丢失，那么<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>会自动通过自己的数据来源重新计算<code>分区</code>，这一切对使用者都是透明的。</p></li><li><p>可以这样来理解：<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a> = 数据 + 算子。</p></li></ul><p>下面是一个极其粗略的<a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>计算任务的执行过程。</p><figure><img src="https://tianmazuo.com/technology/bigdata/spark/spark-02.png" alt="Spark执行任务的大致流程" tabindex="0" loading="lazy"><figcaption>Spark执行任务的大致流程</figcaption></figure><ul><li><p><a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>客户端向集群提交计算任务（此时会生成一个<code>Driver</code>进程。这个<code>Driver</code>进程所在的节点可以是<a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>集群中的节点，也可以就是<a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>客户端节点，它是通过任务提交时的参数决定的）。</p></li><li><p><a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>根据客户端给出的地址，从数据源中拿到数据。这里的数据源大多是情况下都是存储在<a href="https://hadoop.apache.org" target="_blank" rel="noopener noreferrer">Hadoop</a>的<a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html" target="_blank" rel="noopener noreferrer">HDFS</a>中的数据（此时集群主节点的<code>Master</code>进程和从节点的<code>Worker</code>进程相继启动，<code>Master</code>进程负责整个<a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>客户端集群的管理和监控，以及资源的分配，而<code>Worker</code>进程则负责具体计算任务的执行）。</p></li><li><p>由<code>Worker</code>负责启动一个叫做<code>Executor</code>的进程，它负责数据的计算和处理，之后它被反注册到<code>Driver</code>进程中。它将待计算的30万行数据被均匀地分布到了三个节点中，形成了3个<code>分区</code>，每个<code>分区</code>都拿到了10万行数据。<code>Executor</code></p></li><li><p>这3个<code>分区</code>在逻辑上组成了一个<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>。<code>Driver</code>进程会提交干个<code>Task</code>线程到<code>Executor</code>中，<code>Task</code>线程真正地执行计算任务的线程，例如各种算子的执行，都是它来完成的。</p></li><li><p>当前<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>执行完<code>算子</code>所要求的计算后就把数据结果发送给下一个<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>。这里<code>Executor</code>的进程执行<code>Driver</code>分配给它的若干个<code>Task</code>线程，并形成新的<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>中的分区。</p></li><li><p>所有的计算任务执行完成后，<a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>会把计算结果保存到数据存储目的地中，这里的数据存储目的地大多是情况下也都是<a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html" target="_blank" rel="noopener noreferrer">HDFS</a>。</p></li></ul><p>因此，整个<a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>任务执行的大致流程如下。</p><div class="language-shell line-numbers-mode" data-highlighter="shiki" data-ext="shell" data-title="shell" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">\`</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">Driver</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">\`</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> -----┐1</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">  ↑</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> |         </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">↓</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">  | |      </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">\`</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">Master</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">\`</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> -----┐2</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">  | |                    </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">↓</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">  | |                </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">\`</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">Worker</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">\`</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> -----┐3</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">  | |                              </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">↓</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> 4└-+-------------------------</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> \`</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">Executor</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">\`</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">-----┐6</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    |                              </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">↑</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">          |</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">   5└-----------</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> Task</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -------------┘</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">          |</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">                                              ↓</span></span>
<span class="line"><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">                                        \`</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">RDD</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> Partition\`</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>完整的<a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>任务执行过程如下。</p><div class="language-shell line-numbers-mode" data-highlighter="shiki" data-ext="shell" data-title="shell" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">Application（1.开发的Spark应用程序）</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> -&gt; </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">spark-submit（2.提交到Spark集群）</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> -&gt; </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">Driver（3.进程，由spark-submit构造）</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                                                                          |</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                                                                          |</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                                                                          |</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">                                                                       ┌------------------+------------------------------------------------------------------------------┐</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                                                       |                  </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">↓</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">                                                                              ↑</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                                                       |            </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">4.SparkContext</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">   -&gt;   </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">9.初始化完成，继续执行计算</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">  -&gt;  </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">10.（每）执行到Action</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> RDD</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> -&gt; </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">11.创建Job</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                                                       |</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                                                       |                                     </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">┌------------------------------┐</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                                                       |             </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">↙↙</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        ↘↘</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">         |       </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">=======================</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">|</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">=====┐</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                                                       |                                     </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">↓</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">       |                       |     |</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">（16.将TaskSet中的每一个</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">                                                            （Job提交）└--</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt;  </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">12.DAGScheduler</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">  5.TaskScheduler（后台进程）----------------┐</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    |     |     </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">Task提交到Executor）</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">                                                                                    /</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">        （负责连接Master及注册Application）</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">         |    |     |     </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">（Task分配算法）</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">                                                                                   /</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                                    |    |     |</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">                                                                                  /</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                                     |    |     |</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">                                                                                 /</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">               （将自己反向注册到Driver）</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">              |    |     |</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">       18.取出TaskRunner执行（线程池）</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> &lt;</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">-----</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">  17.封装Task（TaskRunner）</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">   &lt;</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">------/-------------</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">     8.Executor（进程）</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> &lt;</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">=================</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">|</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">====</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">|</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">=====┘</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">          （拿到算子及函数的拷贝，反序列化后执行）</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">                                /</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">                        ↑</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                              |    |</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">                                                                              /</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                         |                               |    |</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">                                                                             /</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                          |                               |    |</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">                                                                            /</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                           |                               |    |</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">                                                                           /</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">                        7.Worker</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                            |    |</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">                                                                           ↓</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">                            ↑</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                               |    |</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">                                                                13.将Job划分为多个Stage</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                  |                               |    |</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">                                                                      （划分算法）</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                       |                               |    |</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                                                           |                        </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">6.Master（资源调度算法）</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> &lt;</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">-----------┘</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    |</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">                                                                           ↓</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                                                 |</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">                                                                14.每个Stage创建一个TaskSet</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                                   |</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                                                           |                                                                 |</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                                                           |                                                                 |</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">（15.TaskSet提交给TaskScheduler）</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">                                                                           └-----------------------------------------------------------------┘</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><br><h2 id="两种rdd" tabindex="-1"><a class="header-anchor" href="#两种rdd"><span>两种RDD</span></a></h2><p><a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>把<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>的操作分为两种不同的类型，其实它也对应于两大类不同的<code>算子</code>操作。</p><ul><li><p><code>transformation</code>操作：它会针对已有的<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>创建一个新的<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>，而且具有<a href="https://en.wikipedia.org/wiki/Lazy_loading" target="_blank" rel="noopener noreferrer">Lazy Loading</a>（又叫<code>延迟加载</code>，<code>懒加载</code>）特性，也就是说，<code>transformation</code>操作只是记录了<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>需要执行的任务，但不会立即执行，除非有外部条件触发（也就是由<code>action</code>操作触发）。</p></li><li><p><code>action</code>操作：它是一种任务收尾性的操作，例如遍历结果数据集、reduce汇聚结果、将结果保存到文件等操作都属于这一类。<code>action</code>操作会触发一个<a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>任务执行，从而触发这个<code>action</code>之前所有的<code>transformation</code>的执行，并且它还会将执行的结果返回给<code>Driver</code>程序。</p></li></ul><br><h2 id="三种生成rdd的方式" tabindex="-1"><a class="header-anchor" href="#三种生成rdd的方式"><span>三种生成RDD的方式</span></a></h2><p><a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>是<a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>开发中非常核心的东西，开发中的首要工作就是创建一个初始的<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>。</p><p><a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>提供了三种生成<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>的方式。</p><h3 id="通过集合生成" tabindex="-1"><a class="header-anchor" href="#通过集合生成"><span>通过集合生成</span></a></h3><p>通过集合生成<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>的<a href="https://www.scala-lang.org/api/2.11.12/#package" target="_blank" rel="noopener noreferrer">Scala 2</a>伪代码。</p><div class="language-scala line-numbers-mode" data-highlighter="shiki" data-ext="scala" data-title="scala" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;">// 第2个参数指定分区Partition的个数，不指定的话默认值为2</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">val</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> linesRDD</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> =</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> sc.parallelize(</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">List</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;hello world&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;hello spark&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;hello scala&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">), </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>通过集合生成<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>的<a href="https://www.oracle.com/java/technologies/downloads/archive/" target="_blank" rel="noopener noreferrer">Java</a>伪代码。</p><div class="language-java line-numbers-mode" data-highlighter="shiki" data-ext="java" data-title="java" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;">// 第2个参数指定分区Partition的个数，不指定的话默认值为2</span></span>
<span class="line"><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">JavaRDD</span><span style="--shiki-light:#E45649;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">String</span><span style="--shiki-light:#E45649;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> linesRDD </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> sc</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">parallelize</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">Arrays</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">asList</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;hello world&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;hello spark&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;hello java&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">), </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">);</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="通过本地文件生成" tabindex="-1"><a class="header-anchor" href="#通过本地文件生成"><span>通过本地文件生成</span></a></h3><p><code>textFile()</code>方法支持针对目录、压缩文件以及通配符生成<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>。</p><p>通过本地文件生成<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>的<a href="https://www.scala-lang.org/api/2.11.12/#package" target="_blank" rel="noopener noreferrer">Scala 2</a>伪代码。</p><div class="language-scala line-numbers-mode" data-highlighter="shiki" data-ext="scala" data-title="scala" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;">// 第2个参数指定分区Partition的个数，不指定的话默认值为2</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">val</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> linesRDD</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> =</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> sc.textFile(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;/home/work/wordcount.txt&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>通过本地文件生成<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>的<a href="https://www.oracle.com/java/technologies/downloads/archive/" target="_blank" rel="noopener noreferrer">Java</a>伪代码。</p><div class="language-java line-numbers-mode" data-highlighter="shiki" data-ext="java" data-title="java" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;">// 第2个参数指定分区Partition的个数，不指定的话默认值为2</span></span>
<span class="line"><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">JavaRDD</span><span style="--shiki-light:#E45649;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">String</span><span style="--shiki-light:#E45649;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> linesRDD </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> sc</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">textFile</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;/home/work/wordcount.txt&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">);</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="通过hdfs文件生成" tabindex="-1"><a class="header-anchor" href="#通过hdfs文件生成"><span>通过HDFS文件生成</span></a></h3><p>在这种方式下，<a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>默认会为<a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html" target="_blank" rel="noopener noreferrer">HDFS</a>文件的每一个<code>Block</code>创建一个对应的<code>分区Partition</code>。</p><p>如果通过<code>textFile()</code>方法的第2个参数手动指定分区数量的话，那么这个数量只能比<code>Block</code>，而不能比它少。</p><p>通过<a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html" target="_blank" rel="noopener noreferrer">HDFS</a>文件生成<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>的<a href="https://www.scala-lang.org/api/2.11.12/#package" target="_blank" rel="noopener noreferrer">Scala 2</a>伪代码。</p><div class="language-scala line-numbers-mode" data-highlighter="shiki" data-ext="scala" data-title="scala" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;">// 第2个参数指定分区Partition的个数，不指定的话默认值为2</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">val</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> linesRDD</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> =</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> sc.textFile(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;hdfs://hadoop:9000/spark/job/wordcount.txt&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>通过<a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html" target="_blank" rel="noopener noreferrer">HDFS</a>文件生成<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>的<a href="https://www.oracle.com/java/technologies/downloads/archive/" target="_blank" rel="noopener noreferrer">Java</a>伪代码。</p><div class="language-java line-numbers-mode" data-highlighter="shiki" data-ext="java" data-title="java" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;">// 第2个参数指定分区Partition的个数，不指定的话默认值为2</span></span>
<span class="line"><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">JavaRDD</span><span style="--shiki-light:#E45649;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">String</span><span style="--shiki-light:#E45649;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> linesRDD </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> sc</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">textFile</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;hdfs://hadoop:9000/spark/job/wordcount.txt&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">);</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><br><h2 id="rdd持久化" tabindex="-1"><a class="header-anchor" href="#rdd持久化"><span>RDD持久化</span></a></h2><p><a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>之所以能够实现大数据计算秒级响应的一个很重要的原因就是<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>的<code>持久化</code>。</p><p>但<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>的<code>持久化</code>既不是指的将数据保存在数据库中的那种<code>持久化</code>，又不是指的将数据保存在磁盘中的那种<code>持久化</code>，而是指的 <strong><mark>将RDD持久化在内存中</mark></strong>。</p><p>当对<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>执行持久化操作时，每个节点都会将自己操作的<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>的分区持久化到内存中，并且之后如果再次调用该<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>，那么就直接使用内存中的分区数据。</p><p>也就是说，对于某个<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>被反复执行多次的应用场景，<a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>可以事先执行一次计算，然后将计算结果保存下来（也就是<code>持久化</code>）。当需要再次调用这个<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>执行计算时直接给结果就行了，而不必每次都重复计算，浪费时间和资源——这其实是一种<code>以空间换时间</code>的提升性能的做法。</p><p>特别是一些迭代步骤多或者需要频繁交互的应用场景，这种将<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>持久化的做法对性能的提升特别明显。</p><figure><img src="https://tianmazuo.com/technology/bigdata/spark/spark-03.png" alt="Spark Context Web UI" tabindex="0" loading="lazy"><figcaption>Spark Context Web UI</figcaption></figure><p>如果没有持久化，那么当要再次使用<code>reduceRDD</code>时，最坏的情况就是<a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>顺着链路往回找，把所有的<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>全部重新生成一次。</p><div class="language-scala line-numbers-mode" data-highlighter="shiki" data-ext="scala" data-title="scala" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">              查找                  查找                   查找              查找</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">\`reduceRDD\`   </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">---&gt;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">   \`collectRDD\`   </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">---&gt;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">   \`flatMapRDD\`   </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">---&gt;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">   \`mapRDD\`   </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">---&gt;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">   \`dataRDD\`</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                                                                       |</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                                                                       |</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">                                                                                       |</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">\`reduceRDD\`   </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&lt;---</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">   \`collectRDD\`   </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&lt;---</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">   \`flatMapRDD\`   </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&lt;---</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">   \`mapRDD\`   </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&lt;---</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">       ┘</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">              生成                  生成                   生成              生成</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>要持久化一个<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>，只要调用其<code>cache()</code>或者<code>persist()</code>方法就行了。当该<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>第一次被计算出来时，就会直接缓存在每个节点中。</p><p><a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>的<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>持久化机制是自动容错的：如果持久化的<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>的任何分区丢失了，那么<a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>会自动通过其源<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>（也就是上游<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>），使用<code>transformation</code>操作重新计算该分区。</p><p>关于<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>的持久化有一个小小的误区。</p><div class="language-java line-numbers-mode" data-highlighter="shiki" data-ext="java" data-title="java" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">......</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;">// 正确的调用方式</span></span>
<span class="line"><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">JavaRDD</span><span style="--shiki-light:#E45649;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">String</span><span style="--shiki-light:#E45649;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> rdd </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> context</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">textFile</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;hdfs://hadoop:9000/input/spark.txt&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">).</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">cache</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">();</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;">// 错误的调用方式：这样调用是没有效果的，而且会报错，大量的文件会丢失</span></span>
<span class="line"><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">JavaRDD</span><span style="--shiki-light:#E45649;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">String</span><span style="--shiki-light:#E45649;--shiki-dark:#ABB2BF;">&gt;</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> rdd </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> context</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">textFile</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;hdfs://hadoop:9000/input/spark.txt&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">);</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">rdd</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">cache</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">();</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">......</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>的持久化可以选择不同实现策略，比如可以选择持久化的存储介质，例如，可以将<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>持久化在内存中、磁盘上，使用序列化的方式持久化，使持久化的数据支持多路复用等。</p><table><thead><tr><th style="text-align:center;">持久化级别</th><th style="text-align:left;">说明</th></tr></thead><tbody><tr><td style="text-align:center;">MEMORY_ONLY</td><td style="text-align:left;">以非序列化<a href="https://www.oracle.com/java/technologies/downloads/archive/" target="_blank" rel="noopener noreferrer">Java</a>对象的方式持久化在<code>JVM</code>内存中。如果内存无法存储<a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html" target="_blank" rel="noopener noreferrer">RDD</a>所有的分区，那么那些没有持久化的分区就会在下一次需要使用它的时候被重新计算</td></tr><tr><td style="text-align:center;">MEMORY_AND_DISK</td><td style="text-align:left;">同上，但是当某些分区无法存储在内存中时，会持久化到磁盘中，下次需要使用这些分区时，需要从磁盘上读取</td></tr><tr><td style="text-align:center;">MEMORY_ONLY_SER<br>(<a href="https://www.oracle.com/java/technologies/downloads/archive/" target="_blank" rel="noopener noreferrer">Java</a> and <a href="https://www.scala-lang.org/" target="_blank" rel="noopener noreferrer">Scala</a>)</td><td style="text-align:left;">同<code>MEMORY_ONLY</code>，但是会使用<a href="https://www.oracle.com/java/technologies/downloads/archive/" target="_blank" rel="noopener noreferrer">Java</a>序列化方式，将<a href="https://www.oracle.com/java/technologies/downloads/archive/" target="_blank" rel="noopener noreferrer">Java</a>对象序列化后进行持久化。可以减少内存开销，但是需要进行反序列化，因此会加大<code>CPU</code>开销</td></tr><tr><td style="text-align:center;">MEMORY_AND_DSK_SER<br>(<a href="https://www.oracle.com/java/technologies/downloads/archive/" target="_blank" rel="noopener noreferrer">Java</a> and <a href="https://www.scala-lang.org/" target="_blank" rel="noopener noreferrer">Scala</a>)</td><td style="text-align:left;">同<code>MEMORY_AND_DSK</code>，但是使用序列化方式持久化<a href="https://www.oracle.com/java/technologies/downloads/archive/" target="_blank" rel="noopener noreferrer">Java</a>对象</td></tr><tr><td style="text-align:center;">DISK_ONLY</td><td style="text-align:left;">使用非序列化<a href="https://www.oracle.com/java/technologies/downloads/archive/" target="_blank" rel="noopener noreferrer">Java</a>对象的方式持久化，完全存储到磁盘上</td></tr><tr><td style="text-align:center;">MEMORY_ONLY_2<br>MEMORY_AND_DISK_2<br>等</td><td style="text-align:left;">同<code>MEMORY_ONLY</code>，但尾部加了<code>2</code>的持久化级别，表示会将持久化数据复制一份保存到其他节点，从而在数据丢失时，不需要再次计算，只需要使用备份数据即可</td></tr><tr><td style="text-align:center;">OFF_HEAP<br>(实验性功能)</td><td style="text-align:left;">同<code>MEMORY_ONLY_SER</code>，但将数据存储在堆外内存中，需要启用堆外内存</td></tr></tbody></table><p><a href="https://spark.apache.org/" target="_blank" rel="noopener noreferrer">Spark</a>提供多种持久化级别的主要目的是为了在<code>CPU</code>和<code>内存消耗</code>之间进行取舍，下面是一些通用的持久化级别的选择建议。</p><ul><li><p>应该优先使用<code>MEMORY_ONLY</code>，如果可以缓存所有数据的话，那么就使用这种策略。因为纯内存速度最快，而且没有序列化，不需要消耗CPU进行反序列化操作。</p></li><li><p>如果<code>MEMORY_ONLY</code>策略无法存储的下所有数据的话，那么就使用<code>MEMORY_ONLY_SER</code>将数据序列化后再进行存储，纯内存操作还是非常快，只是要消耗CPU进行反序列化。</p></li><li><p>如果需要快速从失败中恢复，那么就选择带后缀为<code>_2</code>的策略进行数据备份，这样在失败时，就不需要重新计算了。</p></li><li><p>能不使用<code>DISK</code>相关的策略就不使用，有时从磁盘读取数据还不如重新计算一次。</p></li></ul>`,53),n=[t];function l(h,p){return i(),a("div",null,n)}const o=s(r,[["render",l],["__file","rdd.html.vue"]]),g=JSON.parse('{"path":"/technology/bigdata/spark/rdd.html","title":"什么是RDD？","lang":"zh-CN","frontmatter":{"title":"什么是RDD？","icon":"fire","category":["大数据","Spark"],"tag":["大数据","Spark"],"date":"2023-04-08T00:00:00.000Z","isOriginal":true,"star":true,"description":"RDD的概念 RDD（Resilient Distributed Datasets，弹性分布式数据集）是Spark提供的一个非常核心的抽象概念，它是一种可以被分为多个分区（Partition）的数据元素的集合。 默认情况下，RDD的数据是存放在内存中的，而当内存资源不足时，Spark会自动将RDD中的数据写入磁盘（这是它之所以具有弹性的原因）。 分区分...","head":[["meta",{"property":"og:url","content":"https://vuepress-theme-hope-docs-demo.netlify.app/technology/bigdata/spark/rdd.html"}],["meta",{"property":"og:site_name","content":"添码座"}],["meta",{"property":"og:title","content":"什么是RDD？"}],["meta",{"property":"og:description","content":"RDD的概念 RDD（Resilient Distributed Datasets，弹性分布式数据集）是Spark提供的一个非常核心的抽象概念，它是一种可以被分为多个分区（Partition）的数据元素的集合。 默认情况下，RDD的数据是存放在内存中的，而当内存资源不足时，Spark会自动将RDD中的数据写入磁盘（这是它之所以具有弹性的原因）。 分区分..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://tianmazuo.com/technology/bigdata/spark/spark-02.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:author","content":"添码座"}],["meta",{"property":"article:tag","content":"大数据"}],["meta",{"property":"article:tag","content":"Spark"}],["meta",{"property":"article:published_time","content":"2023-04-08T00:00:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"什么是RDD？\\",\\"image\\":[\\"https://tianmazuo.com/technology/bigdata/spark/spark-02.png\\",\\"https://tianmazuo.com/technology/bigdata/spark/spark-03.png\\"],\\"datePublished\\":\\"2023-04-08T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"添码座\\",\\"url\\":\\"https://www.tianmazuo.com/about/\\"}]}"]]},"headers":[{"level":2,"title":"RDD的概念","slug":"rdd的概念","link":"#rdd的概念","children":[]},{"level":2,"title":"两种RDD","slug":"两种rdd","link":"#两种rdd","children":[]},{"level":2,"title":"三种生成RDD的方式","slug":"三种生成rdd的方式","link":"#三种生成rdd的方式","children":[{"level":3,"title":"通过集合生成","slug":"通过集合生成","link":"#通过集合生成","children":[]},{"level":3,"title":"通过本地文件生成","slug":"通过本地文件生成","link":"#通过本地文件生成","children":[]},{"level":3,"title":"通过HDFS文件生成","slug":"通过hdfs文件生成","link":"#通过hdfs文件生成","children":[]}]},{"level":2,"title":"RDD持久化","slug":"rdd持久化","link":"#rdd持久化","children":[]}],"git":{},"readingTime":{"minutes":10.36,"words":3109},"filePathRelative":"technology/bigdata/spark/rdd.md","localizedDate":"2023年4月8日","excerpt":"<h2>RDD的概念</h2>\\n<ul>\\n<li>\\n<p><a href=\\"https://spark.apache.org/docs/latest/rdd-programming-guide.html\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">RDD</a>（<code>Resilient Distributed Datasets，弹性分布式数据集</code>）是<a href=\\"https://spark.apache.org/\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Spark</a>提供的一个非常核心的抽象概念，它是一种可以被分为多个<code>分区</code>（<code>Partition</code>）的数据元素的<code>集合</code>。</p>\\n</li>\\n<li>\\n<p>默认情况下，<a href=\\"https://spark.apache.org/docs/latest/rdd-programming-guide.html\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">RDD</a>的数据是存放在内存中的，而当内存资源不足时，<a href=\\"https://spark.apache.org/\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Spark</a>会自动将<a href=\\"https://spark.apache.org/docs/latest/rdd-programming-guide.html\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">RDD</a>中的数据写入磁盘（这是它之所以具有<code>弹性</code>的原因）。</p>\\n</li>\\n<li>\\n<p><code>分区</code>分布在集群中的不同节点上，所以<a href=\\"https://spark.apache.org/docs/latest/rdd-programming-guide.html\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">RDD</a>中的数据可以被并行操作（这是它之所以具有<code>分布式</code>的原因）。</p>\\n</li>\\n<li>\\n<p><a href=\\"https://spark.apache.org/docs/latest/rdd-programming-guide.html\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">RDD</a>只能通过数据创建，它可以是<a href=\\"https://spark.apache.org/\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Spark</a>支持的任意一种数据集合。</p>\\n</li>\\n<li>\\n<p><a href=\\"https://spark.apache.org/docs/latest/rdd-programming-guide.html\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">RDD</a>最重要的特性就是<code>容错性</code>，它可以自动从节点失败中恢复过来。即如果某个节点上的<code>分区</code>因为节点故障，导致数据丢失，那么<a href=\\"https://spark.apache.org/docs/latest/rdd-programming-guide.html\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">RDD</a>会自动通过自己的数据来源重新计算<code>分区</code>，这一切对使用者都是透明的。</p>\\n</li>\\n<li>\\n<p>可以这样来理解：<a href=\\"https://spark.apache.org/docs/latest/rdd-programming-guide.html\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">RDD</a> = 数据 + 算子。</p>\\n</li>\\n</ul>","autoDesc":true}');export{o as comp,g as data};
